{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuryu6116/AITalker/blob/Master/bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klM-e4W9rEmB",
        "colab_type": "text"
      },
      "source": [
        "# **初期設定**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN9h5ld8rI6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2004aa9-bfed-4e53-982e-a0785e80c758"
      },
      "source": [
        "#Talk_APIのキー設定\n",
        "import os\n",
        "API_Key = \"\" #@param {type:\"string\",title:\"キー入力\"}\n",
        "\n",
        "#GoogleDriveの連携\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYarZ9UdrjzX",
        "colab_type": "text"
      },
      "source": [
        "# 形態素解析(Mecab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMz3y47EshPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.996.5\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a\n",
        "!pip install unidic-lite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm18l1Dj2JTa",
        "colab_type": "text"
      },
      "source": [
        "# BERT(京都大学モデル)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y103oh27KBcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch\n",
        "!pip install ipykernel\n",
        "!pip install pandas\n",
        "!pip install keras\n",
        "!pip install sklearn\n",
        "!pip install keras-bert\n",
        "!pip install transformers\n",
        "!pip install pyknp\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!sudo apt update\n",
        "!sudo apt upgrade\n",
        "!sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
        "\n",
        "!wget wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.2.89-1_amd64.deb\n",
        "!sudo dpkg -i cuda-repo-ubuntu1804_10.2.89-1_amd64.deb\n",
        "!sudo apt update\n",
        "\n",
        "!sudo apt install cuda cuda-drivers\n",
        "!sudo reboot\n",
        "\n",
        "!rm cuda-repo-ubuntu1804_10.2.89-1_amd64.deb\n",
        "\n",
        "!export PATH=\"/usr/local/cuda/bin:$PATH\"\n",
        "!export LD_LIBRARY_PATH=\"/usr/local/cuda/lib64:$LD_LIBRARY_PATH\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uBgfwTVOGod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import MeCab\n",
        "import subprocess\n",
        "import re\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertConfig\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def bert(_text):\n",
        "  return_text=\"\"\n",
        "  config = BertConfig.from_json_file('/content/drive/My Drive/bert/config.json')\n",
        "  model = BertForMaskedLM.from_pretrained('/content/drive/My Drive/bert/pytorch_model.bin', config=config)\n",
        "  bert_tokenizer = BertTokenizer('/content/drive/My Drive/bert/vocab.txt',\n",
        "  do_lower_case=False, do_basic_tokenize=False)\n",
        "  cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "  path = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                            shell=True).communicate()[0]).decode('utf-8')\n",
        "\n",
        "  m=MeCab.Tagger(\"-d {0}\".format(path))\n",
        "  mecab=m.parse(_text)\n",
        "  lines = mecab.split('\\n')\n",
        "  #各行ごとに文章の構成単位に分解\n",
        "  items = (re.split('[\\t]',line) for line in lines)\n",
        "  mecab_list=[]\n",
        "  tokenized_text=[]\n",
        "  [tokenized_text.append(item[0]) for item in items]\n",
        "  print(tokenized_text)\n",
        "  #形態素解析した結果を表示\n",
        "  tokenized_text.insert(0, '[CLS]')\n",
        "  tokenized_list=[]\n",
        "  count=0\n",
        "  masked_index = 0\n",
        "  for text in tokenized_text:\n",
        "      count+=1\n",
        "      if text=='何':\n",
        "          tokenized_list.append('[MASK]')\n",
        "          masked_index=count-1\n",
        "      elif '。' in text:\n",
        "          tokenized_list.append(text)\n",
        "          tokenized_list.append('[SEP]')\n",
        "          count+=2\n",
        "      elif text=='EOS':\n",
        "          count+=1\n",
        "      else:\n",
        "          tokenized_list.append(text)\n",
        "  tokens = bert_tokenizer.convert_tokens_to_ids(tokenized_list)\n",
        "  tokens_tensor = torch.tensor([tokens])\n",
        "  print(tokenized_list)\n",
        "\n",
        "  model.eval()\n",
        "  \n",
        "  tokens_tensor = tokens_tensor.to('cuda')\n",
        "  model.to('cuda')\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    outputs = model(tokens_tensor)\n",
        "    predictions = outputs[0]\n",
        "  \n",
        "    _, predicted_indexes = torch.topk(predictions[0, masked_index], k=3)\n",
        "    predicted_tokens = bert_tokenizer.convert_ids_to_tokens(predicted_indexes.tolist())\n",
        "    \n",
        "    for list_text in predicted_tokens:\n",
        "      return_text+=list_text+','\n",
        "    return return_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQNxC6kvIQ8z",
        "colab_type": "text"
      },
      "source": [
        "# **チャットボットの作成**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbOZPKfIIZ5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from IPython.display import Image\n",
        "def talk_api(message):\n",
        "    talk_url = \"https://api.a3rt.recruit-tech.co.jp/talk/v1/smalltalk\"\n",
        "    payload = {\"apikey\": API_Key, \"query\": message}\n",
        "    response = requests.post(talk_url, data=payload)\n",
        "    try:\n",
        "        return response.json()[\"results\"][0][\"reply\"]\n",
        "    except:\n",
        "        print(response.json())\n",
        "        return \"ごめんなさい。もう一度教えて下さい。\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z675N0TERMK1",
        "colab_type": "text"
      },
      "source": [
        "# **感情極性辞書の作成**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXOTcwKORm01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvN6aT44S1aK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import gensim.models.keyedvectors as word2vec\n",
        "import gensim\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/My Drive/bert/model.vec',binary=False)\n",
        "\n",
        "#「非常にポジティブな単語」と「非常にネガティブな単語」を任意で指定\n",
        "posi_list = ['優れる', '良い','喜ぶ','褒める', 'めでたい','賢い','善い', '適す','天晴',\n",
        " '祝う', '功績','賞','嬉しい','喜び','才知','徳', '才能','素晴らしい','芳しい','称える',\n",
        " '適切','崇める','助ける','抜きんでる','清水','雄雄しい','仕合せ','幸い','吉兆','秀でる']\n",
        "\n",
        "nega_list = ['悪い', '死ぬ', '病気', '酷い', '罵る', '浸ける', '卑しい',\n",
        " '下手', '苦しむ', '苦しい', '付く', '厳しい', '難しい', '殺す', '難い', '荒荒しい',\n",
        " '惨い', '責める', '敵', '背く', '嘲る', '苦しめる', '辛い', '物寂しい', '罰', '不貞腐る',\n",
        " '寒い', '下らない', '残念']\n",
        "\n",
        "def posi_nega_score(x):\n",
        "    #ポジティブ度合いの判定\n",
        "    posi = []\n",
        "    for i in posi_list:\n",
        "        try:\n",
        "            n = model.similarity(i, x)\n",
        "            posi.append(n)\n",
        "        except:\n",
        "            continue\n",
        "    try:\n",
        "        posi_mean = sum(posi)/len(posi)\n",
        "    except:\n",
        "        posi_mean = 0\n",
        "\n",
        "    #ネガティブ度合いの判定\n",
        "    nega = []\n",
        "    for i in nega_list:\n",
        "        try:\n",
        "            n = model.similarity(i, x)\n",
        "            nega.append(n)\n",
        "        except:\n",
        "            continue\n",
        "    try:\n",
        "        nega_mean = sum(nega)/len(nega)\n",
        "    except:\n",
        "        nega_mean = 0\n",
        "    if posi_mean > nega_mean:\n",
        "        return posi_mean\n",
        "    if nega_mean > posi_mean:\n",
        "        return -nega_mean\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9TM6LPAQ5kP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import MeCab\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "\n",
        "def Emotion(_text):\n",
        "  return_text=\"\"\n",
        "  result_num=0\n",
        "  cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "  path = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                            shell=True).communicate()[0]).decode('utf-8')\n",
        "\n",
        "  m=MeCab.Tagger(\"-d {0}\".format(path))\n",
        "  mecab=m.parse(_text)\n",
        "  lines = mecab.split('\\n')\n",
        "  #各行ごとに文章の構成単位に分解\n",
        "  items = (re.split('[\\t]',line) for line in lines)\n",
        "  mecab_list=[]\n",
        "  tokenized_text=[]\n",
        "  [tokenized_text.append(item[0]) for item in items]\n",
        "  #形態素解析した結果を表示\n",
        "  #print(tokenized_text)\n",
        "  for text in tokenized_text:\n",
        "    if(text!='EOS' or text!=''):\n",
        "      result_num+=posi_nega_score(text)\n",
        "  return str(result_num)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUI6HVp9d7mk",
        "colab_type": "text"
      },
      "source": [
        "# **API環境の構築**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrtkrNpugyqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install requests\n",
        "!pip install pycurl\n",
        "!pip uninstall Flask-SocketIO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFgVlE2F0SSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def OpenText(_text):\n",
        "  __text=_text.split(':')\n",
        "  e=__text[1].split('\"')\n",
        "  return e[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xckfYJBfie4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pycurl\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,jsonify\n",
        "from flask import request\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config[\"JSON_AS_ASCII\"] = False\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "result_text=\"\"\n",
        "result=\"\"\n",
        "\n",
        "\n",
        "@app.route(\"/AI\",methods=[\"POST\"])\n",
        "def AIResult():\n",
        "  #Jsonを解析する処理\n",
        "  result_text=OpenText(request.get_data(as_text=True))\n",
        "  result=bert(result_text)\n",
        "\n",
        "  return result\n",
        "\n",
        "@app.route(\"/chat\",methods=[\"POST\"])\n",
        "def ChatResult():\n",
        "  #Jsonを解析する処理\n",
        "  result_text=OpenText(request.get_data(as_text=True))\n",
        "  result = talk_api(result_text)\n",
        "    \n",
        "  return result\n",
        "\n",
        "@app.route(\"/emotion\",methods=[\"POST\"])\n",
        "def EmotionResult():\n",
        "  #Jsonを解析する処理\n",
        "  result_text=OpenText(request.get_data(as_text=True))\n",
        "  result = Emotion(result_text)\n",
        "\n",
        "  return result\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}